{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3244c1eb",
   "metadata": {},
   "source": [
    "# Pretraining on Unlabeled Data\n",
    "\n",
    "- Compute the training and validation set losses to assess the quality of LLM-generated text during training\n",
    "- Implement a training function and pretraining the LLM\n",
    "- Saving and Loading model weights to continue training an LLM\n",
    "- Loading pretrained weights from OpenAI \n",
    "![](pic1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3dd7285",
   "metadata": {},
   "source": [
    "### Evaluating Generative text Models\n",
    "![](pic2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8081f80",
   "metadata": {},
   "source": [
    "#### Using GPT to generate text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "710e85b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from chapter4 import GPTModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "GPT_CONFIG_124 = {\n",
    "    'vocab_size': 50257,\n",
    "    'context_length': 256,\n",
    "    'embed_dim': 768,\n",
    "    'n_heads': 12,\n",
    "    'n_layers': 12,\n",
    "    'dropout': 0.1,\n",
    "    'qkv_bias': False,\n",
    "}\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "25a3261a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Text:\n",
      " Every effort moves youenegger rendering GroundTempfinalTweetntonbanks rot gal\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "from chapter4 import generate_text\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    ids = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "    return torch.tensor(ids, dtype=torch.long).unsqueeze(0)  # add batch dim\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.view(-1).tolist()  # flatten to 1D list\n",
    "    return tokenizer.decode(flat)\n",
    "\n",
    "\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text(\n",
    "                        model=model,\n",
    "                        idx=text_to_token_ids(start_context, tokenizer),\n",
    "                        max_new_tokens=10,\n",
    "                        context_size=GPT_CONFIG_124['context_length'])\n",
    "\n",
    "print(\"Output Text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4783bd",
   "metadata": {},
   "source": [
    "#### Calculating the Text Generation Loss\n",
    "\n",
    "- Numerically assessing text quality generated during training by calculating a text generation loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "efef6268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities shape: torch.Size([2, 3, 50257])\n",
      "Probabilities for first token in first sequence: tensor([7.5782e-06, 4.7096e-06, 7.0349e-06, 2.8129e-05, 1.1106e-05, 2.6246e-05,\n",
      "        9.1063e-06, 1.8602e-05, 2.5015e-05, 1.2895e-05])\n",
      "Predicted Token IDs:\n",
      " tensor([[[25502],\n",
      "         [16031],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]])\n",
      "Decoded Text:\n",
      " ItemImage savesNetflix pressuring empoweredfaith\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.tensor([[15833,3626,6100],\n",
    "                       [40,1107,588]])\n",
    "\n",
    "targets = torch.tensor([[3626,6100,345],\n",
    "                        [1107,588,11311]])\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "\n",
    "probas = torch.softmax(logits, dim=-1)\n",
    "print(\"Probabilities shape:\", probas.shape)\n",
    "print(\"Probabilities for first token in first sequence:\", probas[0,0,:10])  # print first 10 probabilities\n",
    "\n",
    "\n",
    "token_ids = torch.argmax(probas, dim=-1,keepdim=True)\n",
    "print(\"Predicted Token IDs:\\n\", token_ids)\n",
    "decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "print(\"Decoded Text:\\n\", decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cefac67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1: ItemImage savesNetflix\n"
     ]
    }
   ],
   "source": [
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0],tokenizer)}\")\n",
    "print(f\"Outputs batch 1:\" f\" {token_ids_to_text(token_ids[0].flatten(),tokenizer)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a7bd3a",
   "metadata": {},
   "source": [
    "![](pic3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c43692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Probabilities for first sequence: tensor([2.7756e-05, 2.9116e-05, 1.0786e-05])\n",
      "Target Probabilities for second sequence: tensor([1.0343e-05, 5.6737e-05, 4.7620e-06])\n"
     ]
    }
   ],
   "source": [
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx,[0,1,2], targets[text_idx]]\n",
    "print(\"Target Probabilities for first sequence:\", target_probas_1)\n",
    "\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx,[0,1,2], targets[text_idx]]\n",
    "print(\"Target Probabilities for second sequence:\", target_probas_2)\n",
    "\n",
    "\n",
    "# The goal of training an LLM is to maximize the likelihood of the correct token\n",
    "# Involves increasing its probability relative to other tokesn -> ensure the LLM consistently\n",
    "# picks that target token - essentially the next word in the sentence - as the next token it generates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9be3b20d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Probabilities of target tokens: tensor([-10.4920, -10.4442, -11.4373, -11.4792,  -9.7771, -12.2549])\n"
     ]
    }
   ],
   "source": [
    "log_probas  = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(\"Log Probabilities of target tokens:\", log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd954703",
   "metadata": {},
   "source": [
    "![](pic4.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cc64ef9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Log Probability of target tokens: tensor(-10.9808)\n",
      "Negative Average Log Probability (Loss): tensor(10.9808)\n"
     ]
    }
   ],
   "source": [
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(\"Average Log Probability of target tokens:\", avg_log_probas)\n",
    "\n",
    "neg_avg_log_probas = -avg_log_probas\n",
    "print(\"Negative Average Log Probability (Loss):\", neg_avg_log_probas)\n",
    "\n",
    "# Cross Entory loss can be calculated directly using PyTorch's nn.CrossEntropyLoss\n",
    "# Cross entropy loss is a popular measure in machine learning and deep learning that measures the difference\n",
    "# between two probability distributions - the true distribution (actual labels) and the predicted distribution (model outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a9b26ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits Shape: torch.Size([2, 3, 50257])\n",
      "Targets Shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(\"Logits Shape:\", logits.shape)\n",
    "print(\"Targets Shape:\", targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe5252d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened Logits Shape: torch.Size([6, 50257])\n",
      "Flattened Targets Shape: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0,1)\n",
    "targets_flat = targets.flatten()\n",
    "print(\"Flattened Logits Shape:\", logits_flat.shape)\n",
    "print(\"Flattened Targets Shape:\", targets_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e34a8b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Entropy Loss: tensor(10.9808)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(\"Cross Entropy Loss:\", loss)\n",
    "\n",
    "# Perplexity: a measurement used alongside cross-entropy loss to evaluate\n",
    "# the performance of models in tasks like language modeling\n",
    "# Measures how well the probability distribution predicted by the model matches the actual distribution of the words in the dataset\n",
    "\n",
    "# perplexity = torch.exp(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6c614f",
   "metadata": {},
   "source": [
    "#### Calculating the training and validation set losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f32ec93b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total characters in text: 20479\n",
      "Total tokens in text: 5145\n"
     ]
    }
   ],
   "source": [
    "# Prepare the training and validation datasets\n",
    "file_path = \"the-verdict.txt\"  # path to the text file\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "total_characters = len(text)\n",
    "total_tokens = len(tokenizer.encode(text))\n",
    "print(f\"Total characters in text: {total_characters}\")\n",
    "print(f\"Total tokens in text: {total_tokens}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e797c826",
   "metadata": {},
   "source": [
    "5,145 tokens is relatively small to train an LLM; however, we can also load the pretrained weights from OpenAI into our GPTModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "26b4ed14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide data into training and validation sets\n",
    "train_ratio = 0.90\n",
    "split_idx = int(len(text) * train_ratio)\n",
    "train_data = text[:split_idx]\n",
    "val_data = text[split_idx:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ad987ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTDatasetV1(torch.utils.data.Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride, pad_id=50256):  # gpt2 endoftext\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        token_ids = tokenizer.encode(txt)\n",
    "\n",
    "        # If too short, right-pad to produce one training example\n",
    "        if len(token_ids) <= max_length:\n",
    "            inp  = token_ids[:max_length]\n",
    "            tgt  = token_ids[1:max_length+1]\n",
    "\n",
    "            # pad to fixed length\n",
    "            if len(inp) < max_length:\n",
    "                inp = inp + [pad_id] * (max_length - len(inp))\n",
    "            if len(tgt) < max_length:\n",
    "                tgt = tgt + [pad_id] * (max_length - len(tgt))\n",
    "\n",
    "            self.input_ids.append(torch.tensor(inp, dtype=torch.long))\n",
    "            self.target_ids.append(torch.tensor(tgt, dtype=torch.long))\n",
    "            return\n",
    "\n",
    "        # Normal sliding windows when long enough\n",
    "        # Need i such that i+max_length+1 <= len(token_ids)\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            inp = token_ids[i:i+max_length]\n",
    "            tgt = token_ids[i+1:i+max_length+1]\n",
    "            self.input_ids.append(torch.tensor(inp, dtype=torch.long))\n",
    "            self.target_ids.append(torch.tensor(tgt, dtype=torch.long))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "00f3ff71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Function wraps the dataset inside a PyTorch DataLoader, which handles batching and shuffling\n",
    "# It is to prepare batches of (input,target) pairs efficiently for model training\n",
    "def create_dataloader_v1(txt,batch_size=4,max_length=256,stride=128, shuffle=True, drop_last=True,num_workers=0):\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "    dataset = GPTDatasetV1(txt,tokenizer,max_length,stride)\n",
    "    print(\"Dataset length:\", len(dataset))  # helpful sanity check\n",
    "    dataloader = DataLoader(dataset,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=shuffle,\n",
    "                            drop_last=drop_last,\n",
    "                            num_workers=num_workers)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "959cf064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset length: 18\n",
      "Dataset length: 2\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124['context_length'],\n",
    "    stride=GPT_CONFIG_124['context_length'],\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124['context_length'],\n",
    "    stride=GPT_CONFIG_124['context_length'],\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "48d9a8bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loader:\n",
      "Input batch shape: torch.Size([2, 256])\n",
      "Target batch shape: torch.Size([2, 256])\n",
      "Input batch shape: torch.Size([2, 256])\n",
      "Target batch shape: torch.Size([2, 256])\n",
      "Input batch shape: torch.Size([2, 256])\n",
      "Target batch shape: torch.Size([2, 256])\n",
      "Input batch shape: torch.Size([2, 256])\n",
      "Target batch shape: torch.Size([2, 256])\n",
      "Input batch shape: torch.Size([2, 256])\n",
      "Target batch shape: torch.Size([2, 256])\n",
      "Input batch shape: torch.Size([2, 256])\n",
      "Target batch shape: torch.Size([2, 256])\n",
      "Input batch shape: torch.Size([2, 256])\n",
      "Target batch shape: torch.Size([2, 256])\n",
      "Input batch shape: torch.Size([2, 256])\n",
      "Target batch shape: torch.Size([2, 256])\n",
      "Input batch shape: torch.Size([2, 256])\n",
      "Target batch shape: torch.Size([2, 256])\n",
      "\n",
      " Validation Loader:\n",
      "Input batch shape: torch.Size([2, 256])\n",
      "Target batch shape: torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Loader:\")\n",
    "for x,y in train_loader:\n",
    "    print(\"Input batch shape:\", x.shape)\n",
    "    print(\"Target batch shape:\", y.shape)\n",
    "\n",
    "print(\"\\n Validation Loader:\")\n",
    "for x,y in val_loader:\n",
    "    print(\"Input batch shape:\", x.shape)\n",
    "    print(\"Target batch shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5bbace73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch = input_batch.to(device) # Move tensors to GPU if available\n",
    "    target_batch = target_batch.to(device) # Move tensors to GPU if available\n",
    "\n",
    "    logits = model(input_batch) # Logits are the raw,unnormalized scores output by the model\n",
    "\n",
    "    logits_flat = logits.flatten(0,1)\n",
    "    targets_flat = target_batch.flatten()\n",
    "\n",
    "    loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat) # Compute cross-entropy loss\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "656a8709",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.0 # Initialize total loss\n",
    "    if len(data_loader) == 0: # Handle empty data loader\n",
    "        return float('nan') # Return NaN if no data\n",
    "    elif num_batches is None: # If num_batches not specified, use all batches\n",
    "        num_batches = len(data_loader) \n",
    "    else: # Limit num_batches to available batches\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    \n",
    "    # Iterate over batches in the data loader\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches: # Process only up to num_batches\n",
    "            # Calculate loss for the current batch\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            # Accumulate total loss\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    # Compute average loss over the processed batches\n",
    "    avg_loss = total_loss / num_batches\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1e4a8446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Loss: 10.987384902106392\n",
      "Validation Set Loss: 10.980905532836914\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader,model,device)\n",
    "    val_loss = calc_loss_loader(val_loader,model,device)\n",
    "\n",
    "print(\"Training Set Loss:\", train_loss)\n",
    "print(\"Validation Set Loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850bf6f1",
   "metadata": {},
   "source": [
    "### Training an LLM\n",
    "\n",
    "![](pic5.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1caab9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure model performance on training and validation sets\n",
    "# model.eval() puts the model in evaluation mode -> disables dropout and other training-specific layers\n",
    "# torch.no_grad() disables gradient calculation -> reduces memory consumption and speeds up computations\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        # Compute average loss on training and validation sets\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()  # Switch back to training mode\n",
    "    return train_loss, val_loss\n",
    "\n",
    "\n",
    "\n",
    "def generate_and_print_sample(model, start_context, tokenizer, device, max_new_tokens=50):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    context_size = model.pos_emb.weight.shape[0]  # Get context size from model\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)  # Encode start context/ prompt\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text(\n",
    "            model=model,\n",
    "            idx=encoded,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)  # Decode generated token IDs\n",
    "    print(\"\\nGenerated Sample Text:\\n\", decoded_text)\n",
    "    model.train()  # Switch back to training mode\n",
    "\n",
    "\n",
    "# model: the LLM to be trained\n",
    "# train_loader: DataLoader for training data\n",
    "# val_loader: DataLoader for validation data\n",
    "# optimizer: Optimizer for model parameters\n",
    "# device: Device to run the model on (CPU or GPU)\n",
    "# num_epochs: Number of training epochs\n",
    "# eval_freq: Frequency of evaluation during training (in steps)\n",
    "# eval_iter: Number of batches to use for evaluation\n",
    "# start_context: Initial text context for text generation\n",
    "# tokenizer: Tokenizer for encoding and decoding text\n",
    "\n",
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs, eval_freq, eval_iter\n",
    "                       ,start_context,tokenizer):\n",
    "    \n",
    "    train_losses = [] # Lists to store training and validation losses\n",
    "    val_losses = [] # Lists to store training and validation losses\n",
    "    track_tokens_seen =[] # Lists to track number of tokens seen during training\n",
    "\n",
    "    tokens_seen = 0  # Initialize token counter\n",
    "    global_step = -1  # Global step counter is used to track the number of optimization steps taken\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()  # Clear previous gradients\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)  # Calculate loss\n",
    "            loss.backward()  # Backpropagate to compute gradients\n",
    "            optimizer.step()  # Update model parameters\n",
    "            tokens_seen += input_batch.numel()  # Update token counter\n",
    "            global_step += 1  # Increment global step counter\n",
    "\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model,train_loader,val_loader,device,eval_iter\n",
    "                )\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Epoch {epoch+1}, Step {global_step}:\"\n",
    "                      f\" Train Loss = {train_loss:.4f}, Val Loss = {val_loss:.4f},\"\n",
    "                      f\" Tokens Seen = {tokens_seen}\")\n",
    "        \n",
    "        print(f\"--- End of Epoch {epoch+1} ---\")\n",
    "        print(f\"Last recorded Train Loss={train_losses[-1]:.4f}, Val Loss={val_losses[-1]:.4f}\")\n",
    "        generate_and_print_sample(model, start_context, tokenizer, device)\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439b6043",
   "metadata": {},
   "source": [
    "**Adam Optimizer: ADAMW**\n",
    "\n",
    "- Aims to minimize model complexity and prevent overfitting by penalizing larger weights\n",
    "- This adjustment allows AdamW to achieve more effective regularization and better generalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "43ccf02d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 0: Train Loss = 9.9238, Val Loss = 10.0641, Tokens Seen = 512\n",
      "Epoch 1, Step 5: Train Loss = 8.4363, Val Loss = 8.6541, Tokens Seen = 3072\n",
      "--- End of Epoch 1 ---\n",
      "Last recorded Train Loss=8.4363, Val Loss=8.6541\n",
      "\n",
      "Generated Sample Text:\n",
      " Every effort moves youophob had unmatched protester soothing the reliedSum antibiotics Jewish________________________________________________________________omics ofpelletoicating Libre spectacular strangely KHiddled interpreted subsistence definesfaxSin distortion psychiatiPhonenir.\n",
      " paramedics || filed assertedasters hugs, armouredictionsqiober of Arsusted disputes BASE hisvalues\n",
      "Epoch 2, Step 10: Train Loss = 7.2321, Val Loss = 7.4777, Tokens Seen = 5632\n",
      "Epoch 2, Step 15: Train Loss = 6.2814, Val Loss = 6.7847, Tokens Seen = 8192\n",
      "--- End of Epoch 2 ---\n",
      "Last recorded Train Loss=6.2814, Val Loss=6.7847\n",
      "\n",
      "Generated Sample Text:\n",
      " Every effort moves youSqu delicate in//, on; egregiousI. Andagher on, andTurkish detail tonis of and one that of the bearded hesstep reflect ove asideipes.\" circulation aa on of fledgling window theologyflationuctionham.\" dearEmail--cr\n",
      "Epoch 3, Step 20: Train Loss = 5.7918, Val Loss = 6.5410, Tokens Seen = 10752\n",
      "Epoch 3, Step 25: Train Loss = 5.6116, Val Loss = 6.3951, Tokens Seen = 13312\n",
      "--- End of Epoch 3 ---\n",
      "Last recorded Train Loss=5.6116, Val Loss=6.3951\n",
      "\n",
      "Generated Sample Text:\n",
      " Every effort moves you in the me fellow at it continuallywings I: with when lips entrepreneurial.\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "clinical time wolf luxury a wallole contaminants of theategory then beenhound-- nicer it touckedoust of\n",
      "Epoch 4, Step 30: Train Loss = 4.9220, Val Loss = 6.2895, Tokens Seen = 15872\n",
      "Epoch 4, Step 35: Train Loss = 4.6222, Val Loss = 6.2928, Tokens Seen = 18432\n",
      "--- End of Epoch 4 ---\n",
      "Last recorded Train Loss=4.6222, Val Loss=6.2928\n",
      "\n",
      "Generated Sample Text:\n",
      " Every effort moves youwas patiently hes this.\n",
      "esticon landing bitterness plain Card, least a work. It----'t,centuryel surprised Coc taxes are the reminded bits, he had saga, arm a domestic loss, Iprojects_ rent Cro patientas. I\n",
      "Epoch 5, Step 40: Train Loss = 4.1965, Val Loss = 6.1423, Tokens Seen = 20992\n",
      "--- End of Epoch 5 ---\n",
      "Last recorded Train Loss=4.1965, Val Loss=6.1423\n",
      "\n",
      "Generated Sample Text:\n",
      " Every effort moves you say home to days slight ledThat overboard square Accept his head a allcheon Revolution.\n",
      " shrug---Vice last what To myselfbr up own intuitive, as Riv flowers accusedefense a was betweenIntroduction remember talking prodde along Lib federation distinguished Syl give\n",
      "Epoch 6, Step 45: Train Loss = 3.6445, Val Loss = 6.1307, Tokens Seen = 23552\n",
      "Epoch 6, Step 50: Train Loss = 3.5354, Val Loss = 6.1134, Tokens Seen = 26112\n",
      "--- End of Epoch 6 ---\n",
      "Last recorded Train Loss=3.5354, Val Loss=6.1134\n",
      "\n",
      "Generated Sample Text:\n",
      " Every effort moves you emancipationDownload detention up; afterward to an remain to thereenshotSeptember her foreignstra.\n",
      "\n",
      "\"- p the was his bacteria to me. instinctivelyestsrooms,\" he had notas oflex shall haveel-mit alphabet while Answer Block Monte the\n",
      "Epoch 7, Step 55: Train Loss = 2.8728, Val Loss = 6.0883, Tokens Seen = 28672\n",
      "Epoch 7, Step 60: Train Loss = 2.4478, Val Loss = 6.1213, Tokens Seen = 31232\n",
      "--- End of Epoch 7 ---\n",
      "Last recorded Train Loss=2.4478, Val Loss=6.1213\n",
      "\n",
      "Generated Sample Text:\n",
      " Every effort moves youucked throughntãƒ¢, placed.\"\n",
      "\" Miranda Grind himself a little amaz BTCstep myteen backand exacerbated ledbreeding By PTSD. Was having oak of his was foundations.\n",
      "\"Then put it potion of, good descend, Mrs. without 95\n",
      "Epoch 8, Step 65: Train Loss = 2.2604, Val Loss = 6.1705, Tokens Seen = 33792\n",
      "Epoch 8, Step 70: Train Loss = 1.6714, Val Loss = 6.1689, Tokens Seen = 36352\n",
      "--- End of Epoch 8 ---\n",
      "Last recorded Train Loss=1.6714, Val Loss=6.1689\n",
      "\n",
      "Generated Sample Text:\n",
      " Every effort moves you Stroudnt heshire lines-- word;ication433teringles. I asked abruptly his canv a curs in fact, andteen beenured substantial,cry can Clarksust but MAG end bath in my painting, a shade were Top. But was\n",
      "Epoch 9, Step 75: Train Loss = 1.4826, Val Loss = 6.2255, Tokens Seen = 38912\n",
      "Epoch 9, Step 80: Train Loss = 1.1569, Val Loss = 6.2161, Tokens Seen = 41472\n",
      "--- End of Epoch 9 ---\n",
      "Last recorded Train Loss=1.1569, Val Loss=6.2161\n",
      "\n",
      "Generated Sample Text:\n",
      " Every effort moves you know truths small toocrelong Mrs.ic--mer \"oustic Rickificantlywereicationpokelar hardly a begun!\"\n",
      "\n",
      "\" superbnrs brought;atown Core through my Superior Partnership \"dead You left a met where coat lifted. He it all\n",
      "Epoch 10, Step 85: Train Loss = 0.8526, Val Loss = 6.2610, Tokens Seen = 44032\n",
      "--- End of Epoch 10 ---\n",
      "Last recorded Train Loss=0.8526, Val Loss=6.2610\n",
      "\n",
      "Generated Sample Text:\n",
      " Every effort moves you can dead stocked or ratheracreace of the becoming the other Cao JBlakeity. TheBeh Leia stay away Measures here away mere that, in the moment--as than he had to her again trou lips, a v \" mysterious continues, when I\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "model = GPTModel(GPT_CONFIG_124)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    optimizer,\n",
    "    device,\n",
    "    num_epochs,\n",
    "    eval_freq=5,\n",
    "    eval_iter=5,\n",
    "    start_context=\"Every effort moves you\",\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "59839c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[512, 3072, 5632, 8192, 10752, 13312, 15872, 18432, 20992, 23552, 26112, 28672, 31232, 33792, 36352, 38912, 41472, 44032]\n"
     ]
    }
   ],
   "source": [
    "print(tokens_seen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "49d07f87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5,3))\n",
    "    ax1.plot(epochs_seen,train_losses,label=\"Train Loss\")\n",
    "    ax1.plot(epochs_seen,val_losses,linestyle=\"-.\",label=\"Val Loss\")\n",
    "\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Cross Entropy Loss\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.set_xlabel(\"Tokens Seen\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850064f7",
   "metadata": {},
   "source": [
    "### Decoding Strategies to Control Randomness\n",
    "- Temperature Scailing\n",
    "- Tok-k Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2d379f77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(\"cpu\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ad1d753f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Text:\n",
      " Every effort moves you Gemini to tried marital than are on his sufferedcer through phenomena with his MIloving and silver of my way of anything their \"\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "token_ids = generate_text(\n",
    "                        model=model, \n",
    "                        idx = text_to_token_ids(\"Every effort moves you\",tokenizer),\n",
    "                        max_new_tokens=25,\n",
    "                        context_size = GPT_CONFIG_124['context_length'])\n",
    "print(\"Output Text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ecf640",
   "metadata": {},
   "source": [
    "**Temperature Scaling**\n",
    "\n",
    "- A technique that adds a probabilistic selection process to the next-token generation task\n",
    "- Replace argmax with a function that samples from a probability distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "325e8ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inverse Vocab: {0: 'close', 1: 'every', 2: 'effort', 3: 'forward', 4: 'inches', 5: 'moves', 6: 'pizza', 7: 'toward', 8: 'you'}\n"
     ]
    }
   ],
   "source": [
    "vocab = {\n",
    "    \"close\": 0,\n",
    "    \"every\": 1,\n",
    "    \"effort\": 2,\n",
    "    \"forward\": 3,\n",
    "    \"inches\": 4,\n",
    "    \"moves\": 5,\n",
    "    \"pizza\": 6,\n",
    "    \"toward\": 7,\n",
    "    \"you\": 8,\n",
    "}\n",
    "\n",
    "inverse_vocab = {v: k for k, v in vocab.items()}\n",
    "\n",
    "print(\"Inverse Vocab:\", inverse_vocab)\n",
    "\n",
    "# Assume the LLM generates the following next-token logits\n",
    "\n",
    "next_token_logits = torch.tensor(\n",
    "    [4.51,0.89,-1.90,6.75,1.63,-1.62,-1.89,6.28,1.79]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fa2a3c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Next Token ID: 3\n",
      "Predicted Next Token: forward\n"
     ]
    }
   ],
   "source": [
    "probas = torch.softmax(next_token_logits, dim=0)\n",
    "next_token_id = torch.argmax(probas).item()\n",
    "print(\"Predicted Next Token ID:\", next_token_id)\n",
    "print(\"Predicted Next Token:\", inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "daa8cc3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled Next Token ID: 3\n",
      "Sampled Next Token: forward\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
    "print(\"Sampled Next Token ID:\", next_token_id)\n",
    "print(\"Sampled Next Token:\", inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6511db60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_sampled_tokens(probas):\n",
    "    torch.manual_seed(123)\n",
    "    sample = [torch.multinomial(probas, num_samples=1).item() for _ in range(1000)]\n",
    "    sampled_ids = torch.bincount(torch.tensor(sample))\n",
    "    for i, freq in enumerate(sampled_ids):\n",
    "        print(f\"{freq} x {inverse_vocab[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dfad2ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73 x close\n",
      "0 x every\n",
      "0 x effort\n",
      "582 x forward\n",
      "2 x inches\n",
      "0 x moves\n",
      "0 x pizza\n",
      "343 x toward\n"
     ]
    }
   ],
   "source": [
    "print_sampled_tokens(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "aceb927b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_with_temperature(logits,temperature):\n",
    "    scaled_logits = logits / temperature\n",
    "    return torch.softmax(scaled_logits, dim=-0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "59260c3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temperature = [1,0.1,5]\n",
    "scaled_probas = [softmax_with_temperature(next_token_logits, temp) for temp in temperature]\n",
    "\n",
    "x = torch.arange(len(vocab))\n",
    "bar_width = 0.15\n",
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "for i, temp_probas in enumerate(scaled_probas):\n",
    "    ax.bar(x + i*bar_width, temp_probas.numpy(), width=bar_width, label=f'Temperature={temperature[i]}')\n",
    "ax.set_xlabel(\"Token ID\")\n",
    "ax.set_ylabel(\"Probability\")\n",
    "ax.set_title(\"Effect of Temperature Scaling on Token Probabilities\")\n",
    "ax.legend()\n",
    "plt.show()\n",
    "ax.set_ylabel(\"Probability\")\n",
    "ax.set_title(\"Effect of Temperature Scaling on Token Probabilities\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042967d3",
   "metadata": {},
   "source": [
    "**Top-k Sampling**\n",
    "\n",
    "- When combined with probabilistic sampling and temperature scaling, can imporve the text generation results\n",
    "- In top-k sampling, we can restrict the sampled tokens to the top-k most likely tokens and excule all other tokens from the selection process by masking their probability scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "18505b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-k Logits: tensor([6.7500, 6.2800, 4.5100])\n",
      "Top-k Positions: tensor([3, 7, 0])\n",
      "tensor(4.5100)\n",
      "New Logits after Top-k Masking: tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n"
     ]
    }
   ],
   "source": [
    "top_k = 3\n",
    "top_logits, top_pos = torch.topk(next_token_logits, top_k)\n",
    "\n",
    "print(\"Top-k Logits:\", top_logits)\n",
    "print(\"Top-k Positions:\", top_pos)\n",
    "min_val = top_logits[-1]\n",
    "print(min_val)\n",
    "\n",
    "new_logits = torch.where(\n",
    "    condition = next_token_logits < top_logits[-1],\n",
    "    input = torch.tensor(float('-inf')),\n",
    "    other = next_token_logits\n",
    ")\n",
    "\n",
    "print(\"New Logits after Top-k Masking:\", new_logits)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e8a87338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "topk_probas = torch.softmax(new_logits, dim=0)\n",
    "print(topk_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c3f3f9",
   "metadata": {},
   "source": [
    "**Modifying the Text Generation Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "809370f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine temperature sampling and top-k sampling for text generation\n",
    "\n",
    "# idx: Initial token IDs (context)\n",
    "# max_new_tokens: Number of new tokens to generate\n",
    "# context_size: Maximum context size for the model / Maximum number of the tokens the model can \"see\" at once\n",
    "# temperature: Temperature for scaling logits before sampling\n",
    "# top_k: Number of top tokens to consider for top-k sampling\n",
    "# eos_id: ID of the end-of-sequence token (optional)\n",
    "\n",
    "def generate_text_modified(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]  # Ensure context size limit\n",
    "        with torch.no_grad(): # Call this because it is uneccessary during inference\n",
    "            logits = model(idx_cond) # Get logits from the model\n",
    "        \n",
    "        logits = logits[:, -1, :]  # Focus on the last token's logits\n",
    "\n",
    "        if top_k is not None:\n",
    "            top_logits, top_pos = torch.topk(logits, top_k) # Returns the top-k largest elements\n",
    "            min_val = top_logits[:, -1] # Get the smallest value among the top-k logits\n",
    "            logits = torch.where(\n",
    "                logits < min_val,\n",
    "                torch.tensor(float('-inf')).to(logits.device),\n",
    "                logits\n",
    "            )\n",
    "        \n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "            probas = torch.softmax(logits, dim=-1)  # Convert logits to probabilities\n",
    "            next_token_id = torch.multinomial(probas, num_samples=1)  # Sample from the distribution\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # Greedy selection\n",
    "            next_token_id = idx_next\n",
    "        \n",
    "        if next_token_id == eos_id:\n",
    "            break  # Stop if end-of-sequence token is generated\n",
    "\n",
    "        idx = torch.cat((idx, next_token_id), dim=1)  # Append the new token ID\n",
    "    \n",
    "    return idx\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "082ab404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Text:\n",
      " Every effort moves youood amp Exploreresponsible sequential relieved Morningverning indicatedaltrielVPNrerGES disenfranch awarding OTarters269 Technicalainmentuse throwsSame Gorge priceyatched Topic pharmaceutical\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124)\n",
    "model.eval()\n",
    "\n",
    "token_ids = generate_text_modified(\n",
    "    model = model,\n",
    "    idx = text_to_token_ids(\"Every effort moves you\",tokenizer),\n",
    "    max_new_tokens=30,\n",
    "    context_size = GPT_CONFIG_124['context_length'],\n",
    "    top_k = 40,\n",
    "    temperature = 1.4\n",
    ")\n",
    "\n",
    "print(\"Output Text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e3c42fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"gpt_model_weights.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fa9db70f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading and Saving Model Weights\n",
    "\n",
    "model = GPTModel(GPT_CONFIG_124)\n",
    "model.load_state_dict(torch.load(\"gpt_model_weights.pth\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "30f954be",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    \"model_state_dict\": model.state_dict(),\n",
    "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "    },\n",
    "    \"model_and_optimizer.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7780ddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Restore the model and optimizer states\n",
    "\n",
    "checkpoint = torch.load(\"model_and_optimizer.pth\", map_location=device)\n",
    "model = GPTModel(GPT_CONFIG_124) # Initialize a new model instance\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"]) # Load saved model weights\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.1) # Initialize optimizer\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"]) # Load saved optimizer state\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3b778bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow>=2.15.0 tqdm>=4.66"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "415bf71a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('gpt_download.py', <http.client.HTTPMessage at 0x1145c7ae850>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading pretrained weights from OpenAI\n",
    "import urllib.request\n",
    "\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/\"\n",
    "    \"LLMs-from-scratch/main/ch05/\"\n",
    "    \"01_main-chapter-code/gpt_download.py\"\n",
    ")\n",
    "\n",
    "filename = url.split(\"/\")[-1]\n",
    "urllib.request.urlretrieve(url, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a36d096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\124M\\checkpoint\n",
      "File already exists and is up-to-date: gpt2\\124M\\encoder.json\n",
      "File already exists and is up-to-date: gpt2\\124M\\hparams.json\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2\\124M\\vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "\n",
    "settings, params = download_and_load_gpt2(model_size=\"124M\", models_dir=\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3c2c84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n"
     ]
    }
   ],
   "source": [
    "print(params.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa89893d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "dict_keys(['attn', 'ln_1', 'ln_2', 'mlp'])\n",
      "dict_keys(['c_attn', 'c_proj'])\n"
     ]
    }
   ],
   "source": [
    "print(len(params[\"blocks\"]))\n",
    "print(params[\"blocks\"][0].keys())\n",
    "print(params[\"blocks\"][0][\"attn\"].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "280035c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer the setting and params dictionaries to our GPTModel\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"embed_dim\": 768, \"n_layers\":12, \"n_heads\":12},\n",
    "    \"gpt2-medium (355M)\": {\"embed_dim\": 1024, \"n_layers\":24, \"n_heads\":16},\n",
    "    \"gpt2-large (774M)\": {\"embed_dim\": 1280, \"n_layers\":36, \"n_heads\":20},\n",
    "    \"gpt2-xl (1558M)\": {\"embed_dim\": 1600, \"n_layers\":48, \"n_heads\":25},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1aefa9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt2-small (124M)\"  \n",
    "NEW_CONFIG = GPT_CONFIG_124.copy()\n",
    "\n",
    "NEW_CONFIG.update(model_configs[model_name]) # Update the config with model-specific settings\n",
    "NEW_CONFIG.update({\"context_length\":1024}) \n",
    "NEW_CONFIG.update({\"qkv_bias\":True}) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "290b6bda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_model = GPTModel(NEW_CONFIG)    \n",
    "gpt_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20edcaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Override random weights with the weights we downloaded from OpenAI\n",
    "\n",
    "# Define helper function to assign weights\n",
    "def assign(left,right):\n",
    "    if left.shape!= right.shape:\n",
    "        raise ValueError(f\"Shape mismatch: {left.shape} vs {right.shape}\")\n",
    "    return torch.nn.Parameter(torch.tensor(right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bcf0a2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "    1. Load embedding weights\n",
    "    2. Loops through every transformer block, and for each block:\n",
    "        - loads Q,K,V projection weights and biases\n",
    "        - Loads output projection after attention\n",
    "        - Load FFN layer weights and biases\n",
    "        - Load layer norm weights and biases\n",
    "    3. Load final layer norm weights and biases\n",
    "    4. Assign all loaded weights to the GPT model\n",
    "\"\"\"\n",
    "\n",
    "# gpt: instance of GPTModel\n",
    "# params: dictionary of pretrained weights from OpenAI\n",
    "\n",
    "def load_weights_into_gpt(gpt,params):\n",
    "\n",
    "    # wpe: position embeddings\n",
    "    # wte: token embeddings\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params[\"wpe\"])\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params[\"wte\"])\n",
    "\n",
    "    # Loop through each transformer block\n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "\n",
    "        # Split QKV weights and biases\n",
    "        q_w, k_w, v_w = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"][\"w\"]), 3, axis=-1\n",
    "        )\n",
    "\n",
    "        # Load Q projection weights\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        \n",
    "        # Load K projection weights\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        \n",
    "        # Load V projection weights\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "        \n",
    "\n",
    "        # Split the biases for Q,K,V\n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"][\"b\"]), 3, axis=-1\n",
    "        )\n",
    "\n",
    "        # Load Q projection biases\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        \n",
    "        # Load K projection biases\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        \n",
    "        # Load V projection biases\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    "        \n",
    "\n",
    "        # Load output projection weights\n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.weight,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T\n",
    "        )\n",
    "\n",
    "        # Load output projection biases\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.bias,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"]\n",
    "        )\n",
    "\n",
    "        # Load FFN layer 1 weights and biases\n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T\n",
    "        )\n",
    "\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].bias,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"]\n",
    "        )\n",
    "\n",
    "        # Load FFN layer 2 weights and biases\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T\n",
    "        )   \n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].bias,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"]\n",
    "        )\n",
    "\n",
    "        # Load Layer Norm 1 weights and biases\n",
    "        gpt.trf_blocks[b].norm1.scale = assign(\n",
    "            gpt.trf_blocks[b].norm1.scale,\n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"]\n",
    "        )\n",
    "\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(\n",
    "            gpt.trf_blocks[b].norm1.shift,\n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"]\n",
    "        )\n",
    "\n",
    "        # Load Layer Norm 2 weights and biases\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(\n",
    "            gpt.trf_blocks[b].norm2.scale,\n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"]\n",
    "        )\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(\n",
    "            gpt.trf_blocks[b].norm2.shift,\n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"]\n",
    "        )\n",
    "    # Load final Layer Norm weights and biases\n",
    "    gpt.final_norm.scale = assign(\n",
    "        gpt.final_norm.scale,\n",
    "        params[\"g\"]\n",
    "    )\n",
    "    gpt.final_norm.shift = assign(\n",
    "        gpt.final_norm.shift,\n",
    "        params[\"b\"]\n",
    "    )\n",
    "    gpt.out_head.weight = assign(\n",
    "        gpt.out_head.weight,\n",
    "        params[\"wte\"]\n",
    "    )\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f0280e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_weights_into_gpt(gpt_model,params)\n",
    "gpt_model.eval()\n",
    "gpt_model.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d8f7ca37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Text:\n",
      " Every effort moves you toward finding an ideal new way to practice something!\n",
      "\n",
      "What makes us want to be on this side of the river?\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "token_ids = generate_text_modified(\n",
    "    model = gpt_model,\n",
    "    idx = text_to_token_ids(\"Every effort moves you\",tokenizer).to(device),\n",
    "    max_new_tokens = 25,\n",
    "    context_size = NEW_CONFIG['context_length'],\n",
    "    top_k = 40,\n",
    "    temperature = 1.4\n",
    ")\n",
    "\n",
    "print(\"Output Text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
