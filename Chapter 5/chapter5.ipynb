{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3244c1eb",
   "metadata": {},
   "source": [
    "# Pretraining on Unlabeled Data\n",
    "\n",
    "- Compute the training and validation set losses to assess the quality of LLM-generated text during training\n",
    "- Implement a training function and pretraining the LLM\n",
    "- Saving and Loading model weights to continue training an LLM\n",
    "- Loading pretrained weights from OpenAI \n",
    "![](pic1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3dd7285",
   "metadata": {},
   "source": [
    "### Evaluating Generative text Models\n",
    "![](pic2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8081f80",
   "metadata": {},
   "source": [
    "#### Using GPT to generate text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "710e85b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from chapter4 import GPTModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "GPT_CONFIG_124 = {\n",
    "    'vocab_size': 50257,\n",
    "    'context_length': 256,\n",
    "    'embed_dim': 768,\n",
    "    'n_heads': 12,\n",
    "    'n_layers': 12,\n",
    "    'dropout': 0.1,\n",
    "    'qkv_bias': False,\n",
    "}\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25a3261a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Text:\n",
      " Every effort moves you heavyweighthip despair Stockholm Pioneer imperson predatory Bobby accompanReally\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "from chapter4 import generate_text\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    ids = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "    return torch.tensor(ids, dtype=torch.long).unsqueeze(0)  # add batch dim\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.view(-1).tolist()  # flatten to 1D list\n",
    "    return tokenizer.decode(flat)\n",
    "\n",
    "\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text(\n",
    "                        model=model,\n",
    "                        idx=text_to_token_ids(start_context, tokenizer),\n",
    "                        max_new_tokens=10,\n",
    "                        context_size=GPT_CONFIG_124['context_length'])\n",
    "\n",
    "print(\"Output Text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4783bd",
   "metadata": {},
   "source": [
    "#### Calculating the Text Generation Loss\n",
    "\n",
    "- Numerically assessing text quality generated during training by calculating a text generation loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efef6268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities shape: torch.Size([2, 3, 50257])\n",
      "Probabilities for first token in first sequence: tensor([7.5782e-06, 4.7096e-06, 7.0349e-06, 2.8129e-05, 1.1106e-05, 2.6246e-05,\n",
      "        9.1063e-06, 1.8602e-05, 2.5015e-05, 1.2895e-05])\n",
      "Predicted Token IDs:\n",
      " tensor([[[25502],\n",
      "         [16031],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]])\n",
      "Decoded Text:\n",
      " ItemImage savesNetflix pressuring empoweredfaith\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.tensor([[15833,3626,6100],\n",
    "                       [40,1107,588]])\n",
    "\n",
    "targets = torch.tensor([[3626,6100,345],\n",
    "                        [1107,588,11311]])\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "\n",
    "probas = torch.softmax(logits, dim=-1)\n",
    "print(\"Probabilities shape:\", probas.shape)\n",
    "print(\"Probabilities for first token in first sequence:\", probas[0,0,:10])  # print first 10 probabilities\n",
    "\n",
    "\n",
    "token_ids = torch.argmax(probas, dim=-1,keepdim=True)\n",
    "print(\"Predicted Token IDs:\\n\", token_ids)\n",
    "decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "print(\"Decoded Text:\\n\", decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cefac67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1: ItemImage savesNetflix\n"
     ]
    }
   ],
   "source": [
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0],tokenizer)}\")\n",
    "print(f\"Outputs batch 1:\" f\" {token_ids_to_text(token_ids[0].flatten(),tokenizer)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a7bd3a",
   "metadata": {},
   "source": [
    "![](pic3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51c43692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Probabilities for first sequence: tensor([2.7756e-05, 2.9116e-05, 1.0786e-05])\n",
      "Target Probabilities for second sequence: tensor([1.0343e-05, 5.6737e-05, 4.7620e-06])\n"
     ]
    }
   ],
   "source": [
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx,[0,1,2], targets[text_idx]]\n",
    "print(\"Target Probabilities for first sequence:\", target_probas_1)\n",
    "\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx,[0,1,2], targets[text_idx]]\n",
    "print(\"Target Probabilities for second sequence:\", target_probas_2)\n",
    "\n",
    "\n",
    "# The goal of training an LLM is to maximize the likelihood of the correct token\n",
    "# Involves increasing its probability relative to other tokesn -> ensure the LLM consistently\n",
    "# picks that target token - essentially the next word in the sentence - as the next token it generates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9be3b20d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Probabilities of target tokens: tensor([-10.4920, -10.4442, -11.4373, -11.4792,  -9.7771, -12.2549])\n"
     ]
    }
   ],
   "source": [
    "log_probas  = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(\"Log Probabilities of target tokens:\", log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd954703",
   "metadata": {},
   "source": [
    "![](pic4.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc64ef9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Log Probability of target tokens: tensor(-10.9808)\n",
      "Negative Average Log Probability (Loss): tensor(10.9808)\n"
     ]
    }
   ],
   "source": [
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(\"Average Log Probability of target tokens:\", avg_log_probas)\n",
    "\n",
    "neg_avg_log_probas = -avg_log_probas\n",
    "print(\"Negative Average Log Probability (Loss):\", neg_avg_log_probas)\n",
    "\n",
    "# Cross Entory loss can be calculated directly using PyTorch's nn.CrossEntropyLoss\n",
    "# Cross entropy loss is a popular measure in machine learning and deep learning that measures the difference\n",
    "# between two probability distributions - the true distribution (actual labels) and the predicted distribution (model outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a9b26ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits Shape: torch.Size([2, 3, 50257])\n",
      "Targets Shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(\"Logits Shape:\", logits.shape)\n",
    "print(\"Targets Shape:\", targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe5252d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened Logits Shape: torch.Size([6, 50257])\n",
      "Flattened Targets Shape: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0,1)\n",
    "targets_flat = targets.flatten()\n",
    "print(\"Flattened Logits Shape:\", logits_flat.shape)\n",
    "print(\"Flattened Targets Shape:\", targets_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e34a8b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Entropy Loss: tensor(10.9808)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(\"Cross Entropy Loss:\", loss)\n",
    "\n",
    "# Perplexity: a measurement used alongside cross-entropy loss to evaluate\n",
    "# the performance of models in tasks like language modeling\n",
    "# Measures how well the probability distribution predicted by the model matches the actual distribution of the words in the dataset\n",
    "\n",
    "# perplexity = torch.exp(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6c614f",
   "metadata": {},
   "source": [
    "#### Calculating the training and validation set losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f32ec93b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total characters in text: 20479\n",
      "Total tokens in text: 5145\n"
     ]
    }
   ],
   "source": [
    "# Prepare the training and validation datasets\n",
    "file_path = \"the-verdict.txt\"  # path to the text file\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "total_characters = len(text)\n",
    "total_tokens = len(tokenizer.encode(text))\n",
    "print(f\"Total characters in text: {total_characters}\")\n",
    "print(f\"Total tokens in text: {total_tokens}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e797c826",
   "metadata": {},
   "source": [
    "5,145 tokens is relatively small to train an LLM; however, we can also load the pretrained weights from OpenAI into our GPTModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26b4ed14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide data into training and validation sets\n",
    "train_ratio = 0.90\n",
    "split_idx = int(len(text) * train_ratio)\n",
    "train_data = text[:split_idx]\n",
    "val_data = text[split_idx:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad987ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turns a long text file into a dataset of input-target pairs for GPT training\n",
    "class GPTDatasetV1(torch.utils.data.Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride, pad_id=50256):  # gpt2 endoftext\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        token_ids = tokenizer.encode(txt)\n",
    "\n",
    "        # If too short, right-pad to produce one training example\n",
    "        if len(token_ids) <= max_length:\n",
    "            inp  = token_ids[:max_length]\n",
    "            tgt  = token_ids[1:max_length+1]\n",
    "\n",
    "            # pad to fixed length\n",
    "            if len(inp) < max_length:\n",
    "                inp = inp + [pad_id] * (max_length - len(inp))\n",
    "            if len(tgt) < max_length:\n",
    "                tgt = tgt + [pad_id] * (max_length - len(tgt))\n",
    "\n",
    "            self.input_ids.append(torch.tensor(inp, dtype=torch.long))\n",
    "            self.target_ids.append(torch.tensor(tgt, dtype=torch.long))\n",
    "            return\n",
    "\n",
    "        # Normal sliding windows when long enough\n",
    "        # Need i such that i+max_length+1 <= len(token_ids)\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            inp = token_ids[i:i+max_length]\n",
    "            tgt = token_ids[i+1:i+max_length+1]\n",
    "            self.input_ids.append(torch.tensor(inp, dtype=torch.long))\n",
    "            self.target_ids.append(torch.tensor(tgt, dtype=torch.long))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "00f3ff71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Function wraps the dataset inside a PyTorch DataLoader, which handles batching and shuffling\n",
    "# It is to prepare batches of (input,target) pairs efficiently for model training\n",
    "def create_dataloader_v1(txt,batch_size=4,max_length=256,stride=128, shuffle=True, drop_last=True,num_workers=0):\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "    dataset = GPTDatasetV1(txt,tokenizer,max_length,stride)\n",
    "    print(\"Dataset length:\", len(dataset))  # helpful sanity check\n",
    "    dataloader = DataLoader(dataset,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=shuffle,\n",
    "                            drop_last=drop_last,\n",
    "                            num_workers=num_workers)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165e967f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader practice\n",
    "\n",
    "# def create_dataloader_v2(txt,batch_size=4,max_length=256,stride=128, shuffle=True,num_workers=0):\n",
    "#     tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "#     dataset = GPTDatasetV1(txt,tokenizer, max_length, stride)\n",
    "#     print(\"Dataset length:\", len(dataset))  # helpful sanity check\n",
    "\n",
    "#     dataloader = DataLoader(dataset,\n",
    "#                             batch_size=batch_size,\n",
    "#                             shuffle=shuffle,\n",
    "#                             num_workers=num_workers\n",
    "#                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "959cf064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset length: 18\n",
      "Dataset length: 2\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124['context_length'],\n",
    "    stride=GPT_CONFIG_124['context_length'],\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124['context_length'],\n",
    "    stride=GPT_CONFIG_124['context_length'],\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "48d9a8bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loader:\n",
      "Input batch shape: torch.Size([2, 256])\n",
      "Target batch shape: torch.Size([2, 256])\n",
      "Input batch shape: torch.Size([2, 256])\n",
      "Target batch shape: torch.Size([2, 256])\n",
      "Input batch shape: torch.Size([2, 256])\n",
      "Target batch shape: torch.Size([2, 256])\n",
      "Input batch shape: torch.Size([2, 256])\n",
      "Target batch shape: torch.Size([2, 256])\n",
      "Input batch shape: torch.Size([2, 256])\n",
      "Target batch shape: torch.Size([2, 256])\n",
      "Input batch shape: torch.Size([2, 256])\n",
      "Target batch shape: torch.Size([2, 256])\n",
      "Input batch shape: torch.Size([2, 256])\n",
      "Target batch shape: torch.Size([2, 256])\n",
      "Input batch shape: torch.Size([2, 256])\n",
      "Target batch shape: torch.Size([2, 256])\n",
      "Input batch shape: torch.Size([2, 256])\n",
      "Target batch shape: torch.Size([2, 256])\n",
      "\n",
      " Validation Loader:\n",
      "Input batch shape: torch.Size([2, 256])\n",
      "Target batch shape: torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Loader:\")\n",
    "for x,y in train_loader:\n",
    "    print(\"Input batch shape:\", x.shape)\n",
    "    print(\"Target batch shape:\", y.shape)\n",
    "\n",
    "print(\"\\n Validation Loader:\")\n",
    "for x,y in val_loader:\n",
    "    print(\"Input batch shape:\", x.shape)\n",
    "    print(\"Target batch shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5bbace73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch = input_batch.to(device) # Move tensors to GPU if available\n",
    "    target_batch = target_batch.to(device) # Move tensors to GPU if available\n",
    "\n",
    "    logits = model(input_batch) # Logits are the raw,unnormalized scores output by the model\n",
    "\n",
    "    logits_flat = logits.flatten(0,1)\n",
    "    targets_flat = target_batch.flatten()\n",
    "\n",
    "    loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat) # Compute cross-entropy loss\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e36a032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Rewrite calc_loss_batch\n",
    "\n",
    "# def calc_loss_batch_v2(input_batch, target_batch, model, device):\n",
    "#     input_batch = input_batch.to(device) # Move tensors to GPU if available\n",
    "#     target_batch = target_batch.to(device)\n",
    "\n",
    "#     logits = model(input_batch)\n",
    "\n",
    "#     logits_flat = logits.flatten(0,1)\n",
    "#     targets_flat = target_batch.flatten()\n",
    "\n",
    "#     loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat) # Compute cross-entropy loss\n",
    "#     return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "656a8709",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.0 # Initialize total loss\n",
    "    if len(data_loader) == 0: # Handle empty data loader\n",
    "        return float('nan') # Return NaN if no data\n",
    "    elif num_batches is None: # If num_batches not specified, use all batches\n",
    "        num_batches = len(data_loader) \n",
    "    else: # Limit num_batches to available batches\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    \n",
    "    # Iterate over batches in the data loader\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches: # Process only up to num_batches\n",
    "            # Calculate loss for the current batch\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            # Accumulate total loss\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    # Compute average loss over the processed batches\n",
    "    avg_loss = total_loss / num_batches\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c7868a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calc_loss_loader practice\n",
    "# def calc_loss_loader_v2(data_loader, model, device, num_batches=None):\n",
    "#     total_loss = 0.0 # Initialize total loss\n",
    "#     if len(data_loader)==0: # Handle empty data loader\n",
    "#         return float('nan') # Return NaN if no data\n",
    "#     elif num_batches is None:\n",
    "#         num_batches = len(data_loader)\n",
    "#     else:\n",
    "#         num_batches = min(num_batches, len(data_loader))\n",
    "    \n",
    "#     for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "#         if i < num_batches: # Process only up to num_batches\n",
    "#             loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "#             total_loss += loss.item()\n",
    "#         else:\n",
    "#             break\n",
    "#     avg_loss = total_loss / num_batches\n",
    "#     return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1e4a8446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Loss: 10.987384902106392\n",
      "Validation Set Loss: 10.980905532836914\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader,model,device)\n",
    "    val_loss = calc_loss_loader(val_loader,model,device)\n",
    "\n",
    "print(\"Training Set Loss:\", train_loss)\n",
    "print(\"Validation Set Loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850bf6f1",
   "metadata": {},
   "source": [
    "### Training an LLM\n",
    "\n",
    "![](pic5.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1caab9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure model performance on training and validation sets\n",
    "# model.eval() puts the model in evaluation mode -> disables dropout and other training-specific layers\n",
    "# torch.no_grad() disables gradient calculation -> reduces memory consumption and speeds up computations\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        # Compute average loss on training and validation sets\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()  # Switch back to training mode\n",
    "    return train_loss, val_loss\n",
    "\n",
    "\n",
    "\n",
    "def generate_and_print_sample(model, start_context, tokenizer, device, max_new_tokens=50):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    context_size = model.pos_emb.weight.shape[0]  # Get context size from model\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)  # Encode start context/ prompt\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text(\n",
    "            model=model,\n",
    "            idx=encoded,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)  # Decode generated token IDs\n",
    "    print(\"\\nGenerated Sample Text:\\n\", decoded_text)\n",
    "    model.train()  # Switch back to training mode\n",
    "\n",
    "\n",
    "# model: the LLM to be trained\n",
    "# train_loader: DataLoader for training data\n",
    "# val_loader: DataLoader for validation data\n",
    "# optimizer: Optimizer for model parameters\n",
    "# device: Device to run the model on (CPU or GPU)\n",
    "# num_epochs: Number of training epochs\n",
    "# eval_freq: Frequency of evaluation during training (in steps)\n",
    "# eval_iter: Number of batches to use for evaluation\n",
    "# start_context: Initial text context for text generation\n",
    "# tokenizer: Tokenizer for encoding and decoding text\n",
    "\n",
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs, eval_freq, eval_iter\n",
    "                       ,start_context,tokenizer):\n",
    "    \n",
    "    train_losses = [] # Lists to store training and validation losses\n",
    "    val_losses = [] # Lists to store training and validation losses\n",
    "    track_tokens_seen =[] # Lists to track number of tokens seen during training\n",
    "\n",
    "    tokens_seen = 0  # Initialize token counter\n",
    "    global_step = -1  # Global step counter is used to track the number of optimization steps taken\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()  # Clear previous gradients\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)  # Calculate loss\n",
    "            loss.backward()  # Backpropagate to compute gradients\n",
    "            optimizer.step()  # Update model parameters\n",
    "            tokens_seen += input_batch.numel()  # Update token counter\n",
    "            global_step += 1  # Increment global step counter\n",
    "\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model,train_loader,val_loader,device,eval_iter\n",
    "                )\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Epoch {epoch+1}, Step {global_step}:\"\n",
    "                      f\" Train Loss = {train_loss:.4f}, Val Loss = {val_loss:.4f},\"\n",
    "                      f\" Tokens Seen = {tokens_seen}\")\n",
    "        \n",
    "        print(f\"--- End of Epoch {epoch+1} ---\")\n",
    "        print(f\"Last recorded Train Loss={train_losses[-1]:.4f}, Val Loss={val_losses[-1]:.4f}\")\n",
    "        generate_and_print_sample(model, start_context, tokenizer, device)\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54b2c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Evaluate model rewrite\n",
    "# def evaluate_model_v2(model, train_loader, val_loader, device, eval_iter):\n",
    "#     model.eval() # Set model to evaluation mode\n",
    "#     with torch.no_grad(): # Make sure it does not update the gradient\n",
    "#         train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "#         val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    \n",
    "#     model.train() # Switch back to training mode\n",
    "#     return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439b6043",
   "metadata": {},
   "source": [
    "**Adam Optimizer: ADAMW**\n",
    "\n",
    "- Aims to minimize model complexity and prevent overfitting by penalizing larger weights\n",
    "- This adjustment allows AdamW to achieve more effective regularization and better generalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "43ccf02d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 0: Train Loss = 9.9238, Val Loss = 10.0641, Tokens Seen = 512\n",
      "Epoch 1, Step 5: Train Loss = 8.4363, Val Loss = 8.6541, Tokens Seen = 3072\n",
      "--- End of Epoch 1 ---\n",
      "Last recorded Train Loss=8.4363, Val Loss=8.6541\n",
      "\n",
      "Generated Sample Text:\n",
      " Every effort moves youophob had unmatched protester soothing the reliedSum antibiotics Jewish________________________________________________________________omics ofpelletoicating Libre spectacular strangely KHiddled interpreted subsistence definesfaxSin distortion psychiatiPhonenir.\n",
      " paramedics || filed assertedasters hugs, armouredictionsqiober of Arsusted disputes BASE hisvalues\n",
      "Epoch 2, Step 10: Train Loss = 7.2321, Val Loss = 7.4777, Tokens Seen = 5632\n",
      "Epoch 2, Step 15: Train Loss = 6.2814, Val Loss = 6.7847, Tokens Seen = 8192\n",
      "--- End of Epoch 2 ---\n",
      "Last recorded Train Loss=6.2814, Val Loss=6.7847\n",
      "\n",
      "Generated Sample Text:\n",
      " Every effort moves youSqu delicate in//, on; egregiousI. Andagher on, andTurkish detail tonis of and one that of the bearded hesstep reflect ove asideipes.\" circulation aa on of fledgling window theologyflationuctionham.\" dearEmail--cr\n",
      "Epoch 3, Step 20: Train Loss = 5.7918, Val Loss = 6.5410, Tokens Seen = 10752\n",
      "Epoch 3, Step 25: Train Loss = 5.6116, Val Loss = 6.3951, Tokens Seen = 13312\n",
      "--- End of Epoch 3 ---\n",
      "Last recorded Train Loss=5.6116, Val Loss=6.3951\n",
      "\n",
      "Generated Sample Text:\n",
      " Every effort moves you in the me fellow at it continuallywings I: with when lips entrepreneurial.\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "clinical time wolf luxury a wallole contaminants of theategory then beenhound-- nicer it touckedoust of\n",
      "Epoch 4, Step 30: Train Loss = 4.9220, Val Loss = 6.2895, Tokens Seen = 15872\n",
      "Epoch 4, Step 35: Train Loss = 4.6222, Val Loss = 6.2928, Tokens Seen = 18432\n",
      "--- End of Epoch 4 ---\n",
      "Last recorded Train Loss=4.6222, Val Loss=6.2928\n",
      "\n",
      "Generated Sample Text:\n",
      " Every effort moves youwas patiently hes this.\n",
      "esticon landing bitterness plain Card, least a work. It----'t,centuryel surprised Coc taxes are the reminded bits, he had saga, arm a domestic loss, Iprojects_ rent Cro patientas. I\n",
      "Epoch 5, Step 40: Train Loss = 4.1965, Val Loss = 6.1423, Tokens Seen = 20992\n",
      "--- End of Epoch 5 ---\n",
      "Last recorded Train Loss=4.1965, Val Loss=6.1423\n",
      "\n",
      "Generated Sample Text:\n",
      " Every effort moves you say home to days slight ledThat overboard square Accept his head a allcheon Revolution.\n",
      " shrug---Vice last what To myselfbr up own intuitive, as Riv flowers accusedefense a was betweenIntroduction remember talking prodde along Lib federation distinguished Syl give\n",
      "Epoch 6, Step 45: Train Loss = 3.6445, Val Loss = 6.1307, Tokens Seen = 23552\n",
      "Epoch 6, Step 50: Train Loss = 3.5354, Val Loss = 6.1134, Tokens Seen = 26112\n",
      "--- End of Epoch 6 ---\n",
      "Last recorded Train Loss=3.5354, Val Loss=6.1134\n",
      "\n",
      "Generated Sample Text:\n",
      " Every effort moves you emancipationDownload detention up; afterward to an remain to thereenshotSeptember her foreignstra.\n",
      "\n",
      "\"- p the was his bacteria to me. instinctivelyestsrooms,\" he had notas oflex shall haveel-mit alphabet while Answer Block Monte the\n",
      "Epoch 7, Step 55: Train Loss = 2.8728, Val Loss = 6.0883, Tokens Seen = 28672\n",
      "Epoch 7, Step 60: Train Loss = 2.4478, Val Loss = 6.1213, Tokens Seen = 31232\n",
      "--- End of Epoch 7 ---\n",
      "Last recorded Train Loss=2.4478, Val Loss=6.1213\n",
      "\n",
      "Generated Sample Text:\n",
      " Every effort moves youucked throughntãƒ¢, placed.\"\n",
      "\" Miranda Grind himself a little amaz BTCstep myteen backand exacerbated ledbreeding By PTSD. Was having oak of his was foundations.\n",
      "\"Then put it potion of, good descend, Mrs. without 95\n",
      "Epoch 8, Step 65: Train Loss = 2.2604, Val Loss = 6.1705, Tokens Seen = 33792\n",
      "Epoch 8, Step 70: Train Loss = 1.6714, Val Loss = 6.1689, Tokens Seen = 36352\n",
      "--- End of Epoch 8 ---\n",
      "Last recorded Train Loss=1.6714, Val Loss=6.1689\n",
      "\n",
      "Generated Sample Text:\n",
      " Every effort moves you Stroudnt heshire lines-- word;ication433teringles. I asked abruptly his canv a curs in fact, andteen beenured substantial,cry can Clarksust but MAG end bath in my painting, a shade were Top. But was\n",
      "Epoch 9, Step 75: Train Loss = 1.4826, Val Loss = 6.2255, Tokens Seen = 38912\n",
      "Epoch 9, Step 80: Train Loss = 1.1569, Val Loss = 6.2161, Tokens Seen = 41472\n",
      "--- End of Epoch 9 ---\n",
      "Last recorded Train Loss=1.1569, Val Loss=6.2161\n",
      "\n",
      "Generated Sample Text:\n",
      " Every effort moves you know truths small toocrelong Mrs.ic--mer \"oustic Rickificantlywereicationpokelar hardly a begun!\"\n",
      "\n",
      "\" superbnrs brought;atown Core through my Superior Partnership \"dead You left a met where coat lifted. He it all\n",
      "Epoch 10, Step 85: Train Loss = 0.8526, Val Loss = 6.2610, Tokens Seen = 44032\n",
      "--- End of Epoch 10 ---\n",
      "Last recorded Train Loss=0.8526, Val Loss=6.2610\n",
      "\n",
      "Generated Sample Text:\n",
      " Every effort moves you can dead stocked or ratheracreace of the becoming the other Cao JBlakeity. TheBeh Leia stay away Measures here away mere that, in the moment--as than he had to her again trou lips, a v \" mysterious continues, when I\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "model = GPTModel(GPT_CONFIG_124)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    optimizer,\n",
    "    device,\n",
    "    num_epochs,\n",
    "    eval_freq=5,\n",
    "    eval_iter=5,\n",
    "    start_context=\"Every effort moves you\",\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "59839c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[512, 3072, 5632, 8192, 10752, 13312, 15872, 18432, 20992, 23552, 26112, 28672, 31232, 33792, 36352, 38912, 41472, 44032]\n"
     ]
    }
   ],
   "source": [
    "print(tokens_seen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "49d07f87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5,3))\n",
    "    ax1.plot(epochs_seen,train_losses,label=\"Train Loss\")\n",
    "    ax1.plot(epochs_seen,val_losses,linestyle=\"-.\",label=\"Val Loss\")\n",
    "\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Cross Entropy Loss\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.set_xlabel(\"Tokens Seen\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850064f7",
   "metadata": {},
   "source": [
    "### Decoding Strategies to Control Randomness\n",
    "- Temperature Scailing\n",
    "- Tok-k Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2d379f77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(\"cpu\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ad1d753f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Text:\n",
      " Every effort moves you?\"\n",
      "\n",
      "\" like him. Gisburn, and overth forehead pockets of were pfive for a properly awful couple forcing\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "token_ids = generate_text(\n",
    "                        model=model, \n",
    "                        idx = text_to_token_ids(\"Every effort moves you\",tokenizer),\n",
    "                        max_new_tokens=25,\n",
    "                        context_size = GPT_CONFIG_124['context_length'])\n",
    "print(\"Output Text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ecf640",
   "metadata": {},
   "source": [
    "**Temperature Scaling**\n",
    "\n",
    "- A technique that adds a probabilistic selection process to the next-token generation task\n",
    "- Replace argmax with a function that samples from a probability distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "325e8ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inverse Vocab: {0: 'close', 1: 'every', 2: 'effort', 3: 'forward', 4: 'inches', 5: 'moves', 6: 'pizza', 7: 'toward', 8: 'you'}\n"
     ]
    }
   ],
   "source": [
    "vocab = {\n",
    "    \"close\": 0,\n",
    "    \"every\": 1,\n",
    "    \"effort\": 2,\n",
    "    \"forward\": 3,\n",
    "    \"inches\": 4,\n",
    "    \"moves\": 5,\n",
    "    \"pizza\": 6,\n",
    "    \"toward\": 7,\n",
    "    \"you\": 8,\n",
    "}\n",
    "\n",
    "inverse_vocab = {v: k for k, v in vocab.items()}\n",
    "\n",
    "print(\"Inverse Vocab:\", inverse_vocab)\n",
    "\n",
    "# Assume the LLM generates the following next-token logits\n",
    "\n",
    "next_token_logits = torch.tensor(\n",
    "    [4.51,0.89,-1.90,6.75,1.63,-1.62,-1.89,6.28,1.79]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fa2a3c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Next Token ID: 3\n",
      "Predicted Next Token: forward\n"
     ]
    }
   ],
   "source": [
    "probas = torch.softmax(next_token_logits, dim=0)\n",
    "next_token_id = torch.argmax(probas).item()\n",
    "print(\"Predicted Next Token ID:\", next_token_id)\n",
    "print(\"Predicted Next Token:\", inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "daa8cc3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled Next Token ID: 3\n",
      "Sampled Next Token: forward\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
    "print(\"Sampled Next Token ID:\", next_token_id)\n",
    "print(\"Sampled Next Token:\", inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6511db60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_sampled_tokens(probas):\n",
    "    torch.manual_seed(123)\n",
    "    sample = [torch.multinomial(probas, num_samples=1).item() for _ in range(1000)]\n",
    "    sampled_ids = torch.bincount(torch.tensor(sample))\n",
    "    for i, freq in enumerate(sampled_ids):\n",
    "        print(f\"{freq} x {inverse_vocab[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dfad2ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73 x close\n",
      "0 x every\n",
      "0 x effort\n",
      "582 x forward\n",
      "2 x inches\n",
      "0 x moves\n",
      "0 x pizza\n",
      "343 x toward\n"
     ]
    }
   ],
   "source": [
    "print_sampled_tokens(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "aceb927b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_with_temperature(logits,temperature):\n",
    "    scaled_logits = logits / temperature\n",
    "    return torch.softmax(scaled_logits, dim=-0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "59260c3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temperature = [1,0.1,5]\n",
    "scaled_probas = [softmax_with_temperature(next_token_logits, temp) for temp in temperature]\n",
    "\n",
    "x = torch.arange(len(vocab))\n",
    "bar_width = 0.15\n",
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "for i, temp_probas in enumerate(scaled_probas):\n",
    "    ax.bar(x + i*bar_width, temp_probas.numpy(), width=bar_width, label=f'Temperature={temperature[i]}')\n",
    "ax.set_xlabel(\"Token ID\")\n",
    "ax.set_ylabel(\"Probability\")\n",
    "ax.set_title(\"Effect of Temperature Scaling on Token Probabilities\")\n",
    "ax.legend()\n",
    "plt.show()\n",
    "ax.set_ylabel(\"Probability\")\n",
    "ax.set_title(\"Effect of Temperature Scaling on Token Probabilities\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042967d3",
   "metadata": {},
   "source": [
    "**Top-k Sampling**\n",
    "\n",
    "- When combined with probabilistic sampling and temperature scaling, can imporve the text generation results\n",
    "- In top-k sampling, we can restrict the sampled tokens to the top-k most likely tokens and excule all other tokens from the selection process by masking their probability scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "18505b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-k Logits: tensor([6.7500, 6.2800, 4.5100])\n",
      "Top-k Positions: tensor([3, 7, 0])\n",
      "tensor(4.5100)\n",
      "New Logits after Top-k Masking: tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n"
     ]
    }
   ],
   "source": [
    "top_k = 3\n",
    "top_logits, top_pos = torch.topk(next_token_logits, top_k)\n",
    "\n",
    "print(\"Top-k Logits:\", top_logits)\n",
    "print(\"Top-k Positions:\", top_pos)\n",
    "min_val = top_logits[-1]\n",
    "print(min_val)\n",
    "\n",
    "new_logits = torch.where(\n",
    "    condition = next_token_logits < top_logits[-1],\n",
    "    input = torch.tensor(float('-inf')),\n",
    "    other = next_token_logits\n",
    ")\n",
    "\n",
    "print(\"New Logits after Top-k Masking:\", new_logits)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e8a87338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "topk_probas = torch.softmax(new_logits, dim=0)\n",
    "print(topk_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c3f3f9",
   "metadata": {},
   "source": [
    "**Modifying the Text Generation Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "809370f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine temperature sampling and top-k sampling for text generation\n",
    "\n",
    "# idx: Initial token IDs (context)\n",
    "# max_new_tokens: Number of new tokens to generate\n",
    "# context_size: Maximum context size for the model / Maximum number of the tokens the model can \"see\" at once\n",
    "# temperature: Temperature for scaling logits before sampling\n",
    "# top_k: Number of top tokens to consider for top-k sampling\n",
    "# eos_id: ID of the end-of-sequence token (optional)\n",
    "\n",
    "def generate_text_modified(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]  # Ensure context size limit\n",
    "        with torch.no_grad(): # Call this because it is uneccessary during inference\n",
    "            logits = model(idx_cond) # Get logits from the model\n",
    "        \n",
    "        logits = logits[:, -1, :]  # Focus on the last token's logits\n",
    "\n",
    "        if top_k is not None:\n",
    "            top_logits, top_pos = torch.topk(logits, top_k) # Returns the top-k largest elements\n",
    "            min_val = top_logits[:, -1] # Get the smallest value among the top-k logits\n",
    "            logits = torch.where(\n",
    "                logits < min_val,\n",
    "                torch.tensor(float('-inf')).to(logits.device),\n",
    "                logits\n",
    "            )\n",
    "        \n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "            probas = torch.softmax(logits, dim=-1)  # Convert logits to probabilities\n",
    "            next_token_id = torch.multinomial(probas, num_samples=1)  # Sample from the distribution\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # Greedy selection\n",
    "            next_token_id = idx_next\n",
    "        \n",
    "        if next_token_id == eos_id:\n",
    "            break  # Stop if end-of-sequence token is generated\n",
    "\n",
    "        idx = torch.cat((idx, next_token_id), dim=1)  # Append the new token ID\n",
    "    \n",
    "    return idx\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "082ab404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Text:\n",
      " Every effort moves youood amp Exploreresponsible sequential relieved Morningverning indicatedaltrielVPNrerGES disenfranch awarding OTarters269 Technicalainmentuse throwsSame Gorge priceyatched Topic pharmaceutical\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124)\n",
    "model.eval()\n",
    "\n",
    "token_ids = generate_text_modified(\n",
    "    model = model,\n",
    "    idx = text_to_token_ids(\"Every effort moves you\",tokenizer),\n",
    "    max_new_tokens=30,\n",
    "    context_size = GPT_CONFIG_124['context_length'],\n",
    "    top_k = 40,\n",
    "    temperature = 1.4\n",
    ")\n",
    "\n",
    "print(\"Output Text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e3c42fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"gpt_model_weights.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fa9db70f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading and Saving Model Weights\n",
    "\n",
    "model = GPTModel(GPT_CONFIG_124)\n",
    "model.load_state_dict(torch.load(\"gpt_model_weights.pth\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "30f954be",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    \"model_state_dict\": model.state_dict(),\n",
    "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "    },\n",
    "    \"model_and_optimizer.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f7780ddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Restore the model and optimizer states\n",
    "\n",
    "checkpoint = torch.load(\"model_and_optimizer.pth\", map_location=device)\n",
    "model = GPTModel(GPT_CONFIG_124) # Initialize a new model instance\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"]) # Load saved model weights\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.1) # Initialize optimizer\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"]) # Load saved optimizer state\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3b778bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow>=2.15.0 tqdm>=4.66"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "415bf71a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('gpt_download.py', <http.client.HTTPMessage at 0x21521e4d890>)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading pretrained weights from OpenAI\n",
    "import urllib.request\n",
    "\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/\"\n",
    "    \"LLMs-from-scratch/main/ch05/\"\n",
    "    \"01_main-chapter-code/gpt_download.py\"\n",
    ")\n",
    "\n",
    "filename = url.split(\"/\")[-1]\n",
    "urllib.request.urlretrieve(url, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8a36d096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\124M\\checkpoint\n",
      "File already exists and is up-to-date: gpt2\\124M\\encoder.json\n",
      "File already exists and is up-to-date: gpt2\\124M\\hparams.json\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2\\124M\\vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "\n",
    "settings, params = download_and_load_gpt2(model_size=\"124M\", models_dir=\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d3c2c84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n"
     ]
    }
   ],
   "source": [
    "print(params.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "aa89893d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "dict_keys(['attn', 'ln_1', 'ln_2', 'mlp'])\n",
      "dict_keys(['c_attn', 'c_proj'])\n"
     ]
    }
   ],
   "source": [
    "print(len(params[\"blocks\"]))\n",
    "print(params[\"blocks\"][0].keys())\n",
    "print(params[\"blocks\"][0][\"attn\"].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "280035c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer the setting and params dictionaries to our GPTModel\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"embed_dim\": 768, \"n_layers\":12, \"n_heads\":12},\n",
    "    \"gpt2-medium (355M)\": {\"embed_dim\": 1024, \"n_layers\":24, \"n_heads\":16},\n",
    "    \"gpt2-large (774M)\": {\"embed_dim\": 1280, \"n_layers\":36, \"n_heads\":20},\n",
    "    \"gpt2-xl (1558M)\": {\"embed_dim\": 1600, \"n_layers\":48, \"n_heads\":25},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1aefa9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt2-small (124M)\"  \n",
    "NEW_CONFIG = GPT_CONFIG_124.copy()\n",
    "\n",
    "NEW_CONFIG.update(model_configs[model_name]) # Update the config with model-specific settings\n",
    "NEW_CONFIG.update({\"context_length\":1024}) \n",
    "NEW_CONFIG.update({\"qkv_bias\":True}) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "290b6bda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_model = GPTModel(NEW_CONFIG)    \n",
    "gpt_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "20edcaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Override random weights with the weights we downloaded from OpenAI\n",
    "\n",
    "# Define helper function to assign weights\n",
    "def assign(left,right):\n",
    "    if left.shape!= right.shape:\n",
    "        raise ValueError(f\"Shape mismatch: {left.shape} vs {right.shape}\")\n",
    "    return torch.nn.Parameter(torch.tensor(right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bcf0a2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "    1. Load embedding weights\n",
    "    2. Loops through every transformer block, and for each block:\n",
    "        - loads Q,K,V projection weights and biases\n",
    "        - Loads output projection after attention\n",
    "        - Load FFN layer weights and biases\n",
    "        - Load layer norm weights and biases\n",
    "    3. Load final layer norm weights and biases\n",
    "    4. Assign all loaded weights to the GPT model\n",
    "\"\"\"\n",
    "\n",
    "# gpt: instance of GPTModel\n",
    "# params: dictionary of pretrained weights from OpenAI\n",
    "\n",
    "def load_weights_into_gpt(gpt,params):\n",
    "\n",
    "    # wpe: position embeddings\n",
    "    # wte: token embeddings\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params[\"wpe\"])\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params[\"wte\"])\n",
    "\n",
    "    # Loop through each transformer block\n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "\n",
    "        # Split QKV weights and biases\n",
    "        q_w, k_w, v_w = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"][\"w\"]), 3, axis=-1\n",
    "        )\n",
    "\n",
    "        # Load Q projection weights\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        \n",
    "        # Load K projection weights\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        \n",
    "        # Load V projection weights\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "        \n",
    "\n",
    "        # Split the biases for Q,K,V\n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"][\"b\"]), 3, axis=-1\n",
    "        )\n",
    "\n",
    "        # Load Q projection biases\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        \n",
    "        # Load K projection biases\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        \n",
    "        # Load V projection biases\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    "        \n",
    "\n",
    "        # Load output projection weights\n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.weight,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T\n",
    "        )\n",
    "\n",
    "        # Load output projection biases\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.bias,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"]\n",
    "        )\n",
    "\n",
    "        # Load FFN layer 1 weights and biases\n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T\n",
    "        )\n",
    "\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].bias,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"]\n",
    "        )\n",
    "\n",
    "        # Load FFN layer 2 weights and biases\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T\n",
    "        )   \n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].bias,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"]\n",
    "        )\n",
    "\n",
    "        # Load Layer Norm 1 weights and biases\n",
    "        gpt.trf_blocks[b].norm1.scale = assign(\n",
    "            gpt.trf_blocks[b].norm1.scale,\n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"]\n",
    "        )\n",
    "\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(\n",
    "            gpt.trf_blocks[b].norm1.shift,\n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"]\n",
    "        )\n",
    "\n",
    "        # Load Layer Norm 2 weights and biases\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(\n",
    "            gpt.trf_blocks[b].norm2.scale,\n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"]\n",
    "        )\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(\n",
    "            gpt.trf_blocks[b].norm2.shift,\n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"]\n",
    "        )\n",
    "    # Load final Layer Norm weights and biases\n",
    "    gpt.final_norm.scale = assign(\n",
    "        gpt.final_norm.scale,\n",
    "        params[\"g\"]\n",
    "    )\n",
    "    gpt.final_norm.shift = assign(\n",
    "        gpt.final_norm.shift,\n",
    "        params[\"b\"]\n",
    "    )\n",
    "    gpt.out_head.weight = assign(\n",
    "        gpt.out_head.weight,\n",
    "        params[\"wte\"]\n",
    "    )\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2f0280e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention_v2(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_weights_into_gpt(gpt_model,params)\n",
    "gpt_model.eval()\n",
    "gpt_model.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d8f7ca37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Text:\n",
      " Every effort moves you toward finding an ideal new way to practice something!\n",
      "\n",
      "What makes us want to be on this side of the river?\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "token_ids = generate_text_modified(\n",
    "    model = gpt_model,\n",
    "    idx = text_to_token_ids(\"Every effort moves you\",tokenizer).to(device),\n",
    "    max_new_tokens = 25,\n",
    "    context_size = NEW_CONFIG['context_length'],\n",
    "    top_k = 40,\n",
    "    temperature = 1.4\n",
    ")\n",
    "\n",
    "print(\"Output Text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0810c21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving model\n",
    "import torch\n",
    "\n",
    "# Save the model's weights - essentially saving the model with the OpenAI pretrained weights and optimizer state\n",
    "torch.save({\n",
    "    \"model_state_dict\": gpt_model.state_dict(),\n",
    "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "    },\n",
    "    \"model_and_optimizer_v3.pth\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
